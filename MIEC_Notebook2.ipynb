{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad698da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import seaborn as sns\n",
    "from itertools import groupby\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models, Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import *\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "#from keras.optimizers import Adam, SGD\n",
    "from keras.layers import *\n",
    "from keras.metrics import *\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "#from hyperopt import hp, STATUS_OK\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv1D, MaxPooling1D, \\\n",
    "                                    GlobalAveragePooling1D, AveragePooling1D\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "## sequence.pad_sequence(train_x, maxlen=max_words)\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5ef59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = '/stg3/data1/chad/MIEC_data/'\n",
    "path3 = '/stg3/data1/chad/MIEC_data/generalizePairDist_15A_noH_10A.list'\n",
    "file2 = 'MIEC_10A_T_Full_AVER.list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bdf714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########### Preprocessing ##############\n",
    "\n",
    "def df1(path, file):\n",
    "    df = pd.read_csv(path1+file2, delimiter= ' ', header= None)\n",
    "    df.iloc[0,2:]\n",
    "    return df\n",
    "\n",
    "\n",
    "#df1(path1,file2)\n",
    "######################\n",
    "\n",
    "######################\n",
    "\n",
    "def four_inter(data):\n",
    "    df = []\n",
    "#    print(data)\n",
    "    df = data\n",
    "    c_ln = int(df.shape[1])\n",
    "    n_dim = c_ln/4\n",
    "    \n",
    "    lt = [\"VDW\", \"ELE\", \"GB\", \"SA\"]\n",
    "    op = []\n",
    "    \n",
    "    for k, j in enumerate(lt):\n",
    "        if lt[k] == j:\n",
    "            for i in range(int(n_dim)):\n",
    "                f = j + \"_\" + str(i)\n",
    "                op.append(f)\n",
    "            \n",
    "            \n",
    "    res = [list(i) for j, i in groupby(op, lambda a: a.split('_')[0])]\n",
    "    df1 = pd.DataFrame(res[0])\n",
    "    df2 = pd.DataFrame(res[1])\n",
    "    df3 = pd.DataFrame(res[2])\n",
    "    df4 = pd.DataFrame(res[3])\n",
    "    \n",
    "    column_names = pd.concat([df1,df2,df3,df4], axis=1).to_numpy().flatten().tolist()\n",
    "    nam = [\"names\"]\n",
    "    bind = [\"bind\"]\n",
    "\n",
    "    lt_col = nam + bind + column_names\n",
    "    \n",
    "    return lt_col\n",
    "\n",
    "def df_intCol():\n",
    "    df = pd.read_csv(path1+file2, delimiter=' ',names=four_inter(df1(path1,file2)))\n",
    "    return df\n",
    "    \n",
    "def bind():\n",
    "    df = df_intCol()\n",
    "    df_bind = df['bind']\n",
    "    return df_bind\n",
    "\n",
    "def ary_bind():\n",
    "    df_bind = bind()\n",
    "    ary_bindd = np.asarray(df_bind)\n",
    "    return ary_bindd\n",
    "    \n",
    "\n",
    "def df_SclWmax():\n",
    "    df = df_intCol()\n",
    "    df_max = pd.DataFrame({'max': abs(df.iloc[:,2:]).max(axis=1)})\n",
    "    df2 = pd.concat([df, df_max], axis = 1)\n",
    "    df2_drop=df2.drop(columns=['names','bind','max'])\n",
    "    max_values = df2['max']\n",
    "    df2_div = df2_drop.divide(max_values, axis=0)\n",
    "    df2_scaled = pd.concat([df2[['names','bind']],df2_div], axis = 1)\n",
    "    return df2_scaled\n",
    "\n",
    "def df2_ary():\n",
    "    df2_scaled = df_SclWmax()\n",
    "    df2_ary = np.asarray(df2_scaled.iloc[:,2:])\n",
    "    return df2_ary\n",
    "\n",
    "def data_vec():\n",
    "    num_rows = df_SclWmax().shape[0]\n",
    "    ary1 = []\n",
    "    for i in range(num_rows):\n",
    "        ary1.append(df2_scaled.iloc[:,2:].iloc[i].to_numpy().tolist())\n",
    "    return ary1\n",
    "\n",
    "def n_x_4():\n",
    "    ary1 = data_vec()\n",
    "    ary2 = []\n",
    "    for k in range(len(ary1)):\n",
    "        hj = [ary1[k][i:i + 4] for i in range(0, len(ary1[k]), 4)]\n",
    "        ary2.append(hj)\n",
    "    ary3 = np.array(ary2)\n",
    "    return ary3\n",
    "\n",
    "############## Training & Test Data ###############\n",
    "\n",
    "def train_test1():\n",
    "    training_data, testing_data = train_test_split(n_x_4(), test_size=0.1, random_state=10)\n",
    "    x_train3, x_test3, y_train3, y_test3 = train_test_split(n_x_4(), ary_bind(), test_size=0.1, random_state=10)\n",
    "    \n",
    "    return x_train3, x_test3, y_train3, y_test3\n",
    "\n",
    "def train_test2():\n",
    "    x_train2, x_test2, y_train2, y_test2 = train_test_split(df2_ary(), ary_bind(), test_size=0.1, random_state=10)\n",
    "    return x_train2, x_test2, y_train2, y_test2\n",
    "\n",
    "def tr():\n",
    "    x_train2 = train_test2()[0]\n",
    "    tr = np.expand_dims(x_train2, axis=2)\n",
    "    return tr\n",
    "\n",
    "\n",
    "def inp_t2exp():\n",
    "    tr = np.expand_dims(x_train2, axis=2)\n",
    "    return tr\n",
    "\n",
    "################ Contextual Regrssion Model ##################\n",
    "def define_model():\n",
    "    layer0 = Input(shape=tr().shape[1:], name='input')\n",
    "    layer1 = Conv1D(filters=16, kernel_size=4, strides=1, kernel_initializer='glorot_normal',activation='relu',name='Conv1D_1')(layer0)\n",
    "    layer2 = BatchNormalization()(layer1)\n",
    "    layer3 = MaxPool1D(pool_size=1, strides=1)(layer2)\n",
    "\n",
    "    layer4 = Conv1D(filters=12, kernel_size=4, strides=1, kernel_initializer='glorot_normal',activation='relu', name='Conv1D_2')(layer3)\n",
    "    layer5 = MaxPool1D(pool_size=2, strides=2)(layer4)\n",
    "    layer6 = GlobalAveragePooling1D()(layer5)\n",
    "\n",
    "\n",
    "    layer7 = Flatten(name='Flatten_1')(layer6)\n",
    "    layer8 = Dense(12,activation='relu',name='Dense_1')(layer7)\n",
    "    layer9 = Dropout(0.00099,name='dropout_3')(layer8)\n",
    "    layer10 = Dense(12,activation='relu',name='Dense_3')(layer9)\n",
    "    layer11 = Dropout(0.00099,name='dropout_4')(layer10)\n",
    "\n",
    "    ### Contextual regression\n",
    "    layer12 = Dense(166*4,kernel_regularizer=tf.keras.regularizers.l1(0.0001),name='Contextual_Weight')(layer11) ## make first layer\n",
    "    layer13 = Dropout(0.00099,name='dropout_5')(layer12)\n",
    "\n",
    "    #### Dot Product\n",
    "    layer14 = Flatten(name='Flatten_2')(layer0)\n",
    "    layer15 = Multiply()([layer13,layer14]) ## same number of nodes as input feaures\n",
    "\n",
    "    layer16 = Dense(1, activation='sigmoid', kernel_initializer='ones',use_bias=False,name='Sum')(layer15)\n",
    "  #  layer17 = Dense(1, name='Output')(layer16)\n",
    "\n",
    "    model = Model(inputs=layer0, outputs=layer16)\n",
    "    #model.layers[16].trainable = False\n",
    "\n",
    "#    model.summary()\n",
    "    model.compile(SGD(lr=0.01, momentum=0.9),'mean_squared_error', metrics=['accuracy']) ##, momentum=0.9\n",
    "    #model.fit(x_train2, y_train2, batch_size=32, epochs=50, validation_split=0.20)\n",
    "    \n",
    "    return model\n",
    "##############################################################################\n",
    "\n",
    "def gen_pair():\n",
    "\n",
    "    df5 = pd.read_csv(path3, sep='\\\\t', header=None)\n",
    "    df5.columns = ['res1','res2','prot_res','lig_res','arb1','dist','arb2']\n",
    "    #pd.set_option('display.max_rows', None)\n",
    "    #pd.set_option('display.max_columns', None)\n",
    "    return df5\n",
    "   \n",
    "################# This is to Index weights to rank them #####################\n",
    "def four_inter2(data):\n",
    "    df = []\n",
    "#    print(data)\n",
    "    df = data\n",
    "    c_ln = int(df.shape[1])\n",
    "    n_dim = c_ln/4\n",
    "    \n",
    "    lt = [\"VDW\", \"ELE\", \"GB\", \"SA\"]\n",
    "    op = []\n",
    "    \n",
    "    for k, j in enumerate(lt):\n",
    "        if lt[k] == j:\n",
    "            for i in range(int(n_dim)):\n",
    "                f = j + \"_\" + str(i)\n",
    "                op.append(f)\n",
    "            \n",
    "            \n",
    "    res = [list(i) for j, i in groupby(op, lambda a: a.split('_')[0])]\n",
    "    ddf1 = pd.DataFrame(res[0])\n",
    "    ddf2 = pd.DataFrame(res[1])\n",
    "    ddf3 = pd.DataFrame(res[2])\n",
    "    ddf4 = pd.DataFrame(res[3])\n",
    "    \n",
    "    column_names = pd.concat([ddf1,ddf2,ddf3,ddf4], axis=1).to_numpy().flatten().tolist()\n",
    "\n",
    "    lt_col = column_names\n",
    "    \n",
    "    return lt_col\n",
    "\n",
    "############################ get predictions ################\n",
    "def pred_ary(x_test2):\n",
    "    x_test2 = test_train2()[1]\n",
    "    pre = abs(np.asarray(model.predict(x_test2).round()))\n",
    "    y_test2\n",
    "    ld = [x[0] for x in pre]\n",
    "    ints = [int(item) for item in ld]\n",
    "    pre_ary = np.array(ints)\n",
    "    return pre_ary\n",
    "############################## Get Weights ##################\n",
    "\n",
    "def contx_wt(): ### Remember you need to fit model before using this...\n",
    "    gh = model.get_layer(name='Contextual_Weight').get_weights()[0]\n",
    "    gh2 = model.get_layer(name='Contextual_Weight').get_weights()[1]\n",
    "    df2 = pd.DataFrame(gh).T\n",
    "    return df2\n",
    "\n",
    "def label_sort_wt():\n",
    "    df2=contx_wt().T\n",
    "    df2.columns = four_inter2(df2)\n",
    "    df_abs = abs(df2)\n",
    "    df_sort = df_abs.sort_values(by=0, ascending=False,axis=1)\n",
    "    return df_sort\n",
    "\n",
    "def label_wt():\n",
    "    df2=contx_wt().T\n",
    "\n",
    "    df2.columns = four_inter2(df2)\n",
    "    df_abs = abs(df2)\n",
    "\n",
    "    df_rk = df_abs.sort_values(by=0, ascending=False,axis=1)\n",
    "    df_rk = round(df_rk.iloc[:,0:30],15)\n",
    "    df_rkw = pd.DataFrame(df_rk.iloc[0]).reset_index()[0]\n",
    "    df_rkw = pd.DataFrame(df_rkw)\n",
    "    df_rkw.columns = ['weights']\n",
    "    return df_rk, df_rkw\n",
    "\n",
    "def gen_pair_wt():\n",
    "    df5 = gen_pair()\n",
    "    df_rk = label_wt()[0]\n",
    "    df_rkw = label_wt()[1]\n",
    "    df = df_intCol()\n",
    "    df_rk.columns\n",
    "    df_2lt = list(df_rk.columns)\n",
    "\n",
    "    df_2lt\n",
    "    int_term = []\n",
    "    int_pair = []\n",
    "    for i in range(len(df_2lt)):\n",
    "#    print(df_2lt[i].split('_'))\n",
    "        int_term.append(df_2lt[i].split('_')[0])\n",
    "        int_pair.append(df_2lt[i].split('_')[1])\n",
    "    \n",
    "#np.sort(int_pair)\n",
    "#sorted(int_pair, key=int, reverse=False)\n",
    "\n",
    "## Put them into DFs in case needed....\n",
    "    INT_TERM = pd.DataFrame(int_term, columns=['terms'])\n",
    "    INT_PAIR = pd.DataFrame(int_pair, columns=['pair'])\n",
    "\n",
    "    pd.concat([INT_TERM,INT_PAIR], axis=1)\n",
    "\n",
    "\n",
    "## We need to even out vectors...so lets Filter data base on the limit of DF5\n",
    "    lt_pr = []\n",
    "    ind = []\n",
    "\n",
    "    for j in int_pair:\n",
    "        j = int(j)\n",
    "        if j < df5.shape[0]:\n",
    "            lt_pr.append(df5.iloc[j])\n",
    " #       ind.append(df_rk.iloc[j]) \n",
    "        \n",
    "\n",
    "    lt_pr[0]        \n",
    "#ind[0]\n",
    "    int_pair\n",
    "    f = pd.DataFrame(lt_pr)\n",
    "    g = pd.DataFrame(df_rk.columns,columns=['terms'])\n",
    "#h = pd.DataFrame()\n",
    "#pd.concat([g,f])\n",
    "                 \n",
    "##split data in into different columns\n",
    "\n",
    "    h = pd.DataFrame(int_term, columns=['int_term'])\n",
    "    gh = pd.concat([g,h,df_rkw],axis=1)\n",
    "\n",
    "\n",
    "    #df_en = df[gh['terms']]\n",
    "    ###################### Multiplying weights\n",
    "    #df_en_sc = df_en.multiply(np.array(df_rkw.T), axis='columns')\n",
    "    #df_en.multiply(np.array(df_rkw.T), axis='columns')\n",
    "    return gh\n",
    "\n",
    "############# Plotting Functions #################\n",
    "def plot_cv():\n",
    "    X, y = train_test2()[0], train_test2()[2]\n",
    "    # get the models to evaluate\n",
    "    models = define_models()\n",
    "    # evaluate the models and store results\n",
    "    results, names = list(), list()\n",
    "    for name, model in models.items():\n",
    "        scores = evaluate_model(model, X, y)\n",
    "        results.append(scores)\n",
    "        names.append(name)\n",
    "        print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "    pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "def plot_acc_los():\n",
    "    model = define_model()\n",
    "    history = model.fit(train_test2()[0], train_test2()[2], batch_size=16, epochs=15, validation_split=0.20)#, callbacks=[check_cb]) \n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_roc():\n",
    "#    model1 = define_model()\n",
    "#    history = model1.fit(train_test2()[0], train_test2()[2], batch_size=16, epochs=15, validation_split=0.20)#, callbacks=[check_cb]) \n",
    "    \n",
    "    \n",
    "    rfc = RandomForestClassifier(n_estimators=75, max_features=4,max_samples=0.6, random_state=5)\n",
    "    rfc.fit(train_test2()[0], train_test2()[2])\n",
    "\n",
    "    clf2 = SVC(kernel='poly', C=1, coef0=1, degree=5)\n",
    "    clf2.fit(train_test2()[0], train_test2()[2]) \n",
    "    #rfc_y_pred_proba = rfc.predict_proba(train_test2()[0])\n",
    "    #rfc_y_pred_proba_positive = rfc_y_pred_proba[:, 1] \n",
    "\n",
    "    ax = plt.gca()\n",
    "\n",
    "    rfc_disp = RocCurveDisplay.from_estimator(rfc, train_test2()[0], train_test2()[2], ax=ax, alpha=0.8)\n",
    "    #clf_disp = RocCurveDisplay.from_estimator(clf, x_test2, y_test2, ax=ax, alpha=0.8)\n",
    "    clf2_disp = RocCurveDisplay.from_estimator(clf2, train_test2()[0], train_test2()[2], ax=ax, alpha=0.8)\n",
    "\n",
    "#    y_pred= model1.predict(train_test2()[1])\n",
    "#    fpr, tpr, _ = metrics.roc_curve(train_test2()[1],  y_pred)\n",
    "#    auc = metrics.roc_auc_score(train_test2()[1], y_pred)\n",
    "#    plt.plot(fpr,tpr,label=\"CCR(auc=\"+str(auc.round(3))+\")\")\n",
    "#    plt.legend(loc=4)\n",
    "#    plt.show()\n",
    "\n",
    "def plot_som():\n",
    "    X, y = train_test2()[0], train_test2()[2]\n",
    "    # get the models to evaluate\n",
    "    models = define_models()\n",
    "    # evaluate the models and store results\n",
    "    results, names = list(), list()\n",
    "    for name, model in models.items():\n",
    "        scores = evaluate_model(model, X, y)\n",
    "        results.append(scores)\n",
    "        names.append(name)\n",
    "        print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "    pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "    pyplot.show()\n",
    "\n",
    "################ Fitting Model ##################\n",
    "def fit_model():\n",
    "    model = define_model()\n",
    "    #model.compile(optimizer='Adam',loss='mse',metrics =['accuracy'])\n",
    "   # model.compile(SGD(lr=0.01, momentum=0.9),'mean_squared_error', metrics=['accuracy']) ##, momentum=0.9\n",
    "    earlystop_cb = EarlyStopping(monitor='val_loss', patience=15, verbose=1, mode='min')\n",
    "    check_cb = ModelCheckpoint('bestparams2.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    history = model.fit(train_test2()[0], train_test2()[2], batch_size=16, epochs=150, validation_split=0.20, callbacks=[check_cb]) \n",
    "\n",
    "########## Evaluate Model with Cross-Validation Procedure #######################\n",
    "### Note if you want to loop over kfold you need to change this so it is looopable\n",
    "\n",
    "def evaluate_model(dataX, dataY, n_folds):\n",
    "    scores, histories = list(), list()\n",
    "    # prepare cross validation\n",
    "    kfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(dataX):\n",
    "    # define model\n",
    "        model = define_model()\n",
    "        # select rows for train and test\n",
    "        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "        # fit model\n",
    "        earlystop_cb = EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='min')\n",
    "        check_cb = ModelCheckpoint('bestparams2.h5', monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "        history = model.fit(x_train2, y_train2, batch_size=32, epochs=50, validation_split=0.20, callbacks=[check_cb],verbose=0) \n",
    "        # evaluate model\n",
    "        _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "        print('> %.3f' % (acc * 100.0))\n",
    "        # append scores\n",
    "        scores.append(acc)\n",
    "        histories.append(history)\n",
    "    return scores, histories\n",
    "\n",
    "###### Lets do some Cross-validation\n",
    "def cross_val1():\n",
    "    # fix random seed for reproducibility\n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "    # split into input (X) and output (Y) variables\n",
    "    X, Y = train_test2()[0], train_test2()[2]\n",
    "    # define 10-fold cross validation test harness\n",
    "    kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "    cvscores = []\n",
    "    for train, test in kfold.split(train_test2()[0], train_test2()[2]):\n",
    "      # create model\n",
    "        model = define_model()\n",
    "        # Compile model\n",
    "        #model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "        # Fit the model\n",
    "        model.fit(X[train], Y[train], epochs=50, batch_size=10, verbose=0)\n",
    "        # evaluate the model\n",
    "        scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        cvscores.append(scores[1] * 100)\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "    return cvscores\n",
    "#evaluate_model2():\n",
    "    \n",
    "    \n",
    "\n",
    "#def evaluate_model2(X, Y, repeats):\n",
    "# prepare the cross-validation procedure\n",
    "#cv = RepeatedKFold(n_splits=5, n_repeats=repeats, random_state=1)\n",
    "## create model\n",
    "#model = define_model()\n",
    "## evaluate model\n",
    "#scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "#return scores\n",
    "#plot_acc_los()\n",
    "#plot_roc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a8535",
   "metadata": {},
   "source": [
    "# Cross-validation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16513bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/stg3/data1/chad/anaconda3/envs/python3.10/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 77.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/stg3/data1/chad/anaconda3/envs/python3.10/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 76.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/stg3/data1/chad/anaconda3/envs/python3.10/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 77.81%\n",
      "77.14% (+/- 0.55%)\n"
     ]
    }
   ],
   "source": [
    "# MLP for Pima Indians Dataset with 10-fold cross validation\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "# split into input (X) and output (Y) variables\n",
    "X, Y = train_test2()[0], train_test2()[2]\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(train_test2()[0], train_test2()[2]):\n",
    "  # create model\n",
    "    model = define_model()\n",
    "    # Compile model\n",
    "    #model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(X[train], Y[train], batch_size=32, epochs=15, validation_split=0.20,verbose=0)   \n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9120f01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(cvscores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce14c0",
   "metadata": {},
   "source": [
    "# Cross-validation of SVM & RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "962ba654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">4 0.780 (0.007)\n",
      ">8 0.791 (0.007)\n",
      ">12 0.796 (0.007)\n",
      ">16 0.797 (0.009)\n",
      ">20 0.798 (0.005)\n",
      ">24 0.800 (0.004)\n",
      ">28 0.798 (0.003)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# explore the number of selected features for RFE\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "        X, y = train_test2()[0], train_test2()[2]\n",
    "        return X, y\n",
    "    \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "        models = dict()\n",
    "        for i in range(4,32,4):\n",
    "            models[str(i)] = RandomForestClassifier(n_estimators=i)\n",
    "                #rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=i)\n",
    "                #models = RandomForestClassifier(max_features=i)\n",
    "                #models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "        return models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "        cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=3, random_state=1)\n",
    "        scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "        return scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "        scores = evaluate_model(model, X, y)\n",
    "        results.append(scores)\n",
    "        names.append(name)\n",
    "        print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e4d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
